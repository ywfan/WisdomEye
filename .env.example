# ======================= LLM 配置 =======================
# 兼容 OpenAI 格式的 /chat/completions 接口
# 将下方占位符替换为真实值，并保存在本地 .env（不要提交到版本库）

# 默认提供商与模型（示例）
LLM_DEFAULT_PROVIDER=dashscope
LLM_DEFAULT_MODEL=deepseek-v3.2-exp

# 阿里百炼（示例）
DASHSCOPE_API_KEY=your_dashscope_key
DASHSCOPE_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1

# AIHub（示例）
AIHUB_API_KEY=your_aihub_key
AIHUB_BASE_URL=https://aihubmix.com/v1

# MoonShot（示例）
MOONSHOT_API_KEY=your_moonshot_key
MOONSHOT_BASE_URL=https://api.moonshot.cn/v1

# ================== 网络搜索配置 =======================
# Tavily 搜索
TAVILY_API_KEY=your_tavily_key

# Bocha AI Search
BOCHA_BASE_URL=https://api.bochaai.com/v1/ai-search
BOCHA_WEB_SEARCH_API_KEY=your_bocha_key

# ================== 速率与预算控制 =====================
# 每进程预算上限（0 表示不限制）
BUDGET_MAX_LLM_CALLS=0
BUDGET_MAX_SEARCH_CALLS=0

# 速率限制窗口与令牌（示例值）
LLM_RATE_LIMIT=60
LLM_RATE_WINDOW=60
SEARCH_RATE_LIMIT=120
SEARCH_RATE_WINDOW=60

# ================== 其他可选设置 =======================
# 最大 tokens（空则由服务端默认）
LLM_DEFAULT_MAX_TOKENS=

# 超时时间与重试策略由代码内默认控制；如需覆盖，可在适配层中扩展环境读取逻辑
