# ç»¼åˆé—®é¢˜åˆ†æä¸ä¿®å¤æ–¹æ¡ˆ - æ—æŒºç®€å†æŠ¥å‘Š

## ğŸ“‹ é—®é¢˜æ±‡æ€»è¡¨

æ ¹æ®å®é™…ç”Ÿæˆçš„ `resume_final.html` æŠ¥å‘Šï¼Œä»ä½¿ç”¨è€…è§’åº¦å‘ç°ä»¥ä¸‹10ä¸ªä¸»è¦é—®é¢˜ï¼š

| # | é—®é¢˜ç±»åˆ« | ä¸¥é‡ç¨‹åº¦ | å½“å‰çŠ¶æ€ | ç”¨æˆ·å½±å“ | ä¼˜å…ˆçº§ |
|---|---------|----------|---------|---------|---------|
| 1 | **å­¦æœ¯æŒ‡æ ‡å®Œå…¨ä¸ºç©º** | ğŸ”´ ä¸¥é‡ | h-index/citationså…¨éƒ¨ç©ºç™½ | æ— æ³•è¯„ä¼°å­¦æœ¯æ°´å¹³ | P0 |
| 2 | **ä½œè€…è´¡çŒ®åº¦å…¨ä¸º0** | ğŸ”´ ä¸¥é‡ | ç‹¬ç«‹æ€§0.00, ç¬¬ä¸€ä½œè€…0% | è¯¯åˆ¤å€™é€‰äººèƒ½åŠ› | P0 |
| 3 | **é£é™©è¯„ä¼°ä½¿ç”¨è‹±æ–‡** | ğŸ”´ ä¸¥é‡ | å…¨éƒ¨è‹±æ–‡æè¿° | ç”¨æˆ·ä½“éªŒæå·® | P0 |
| 4 | **è¯æ®é“¾è¿½æº¯ä¸ºç©º** | ğŸ”´ ä¸¥é‡ | 5ä¸ªç»´åº¦å…¨æ— å†…å®¹ | ç¼ºå°‘å…³é”®è¯æ® | P1 |
| 5 | **ç ”ç©¶è„‰ç»œå¾—åˆ†ä¸º0** | ğŸ”´ ä¸¥é‡ | è¿ç»­æ€§0.00, æˆç†Ÿåº¦Unknown | æ— æ³•è¯„ä¼°ç ”ç©¶æ–¹å‘ | P1 |
| 6 | **å‚è€ƒæ¥æºæ•°é‡ä¸º0** | ğŸ”´ ä¸¥é‡ | sourcesåˆ—è¡¨ä¸ºç©º | æ— æ³•è¿½æº¯ä¿¡æ¯ | P1 |
| 7 | **è´¨é‡å¾—åˆ†ä¸º0** | ğŸŸ¡ ä¸­ç­‰ | äº§å‡ºæ—¶é—´çº¿è´¨é‡0.0 | å½±å“ç»¼åˆè¯„åˆ† | P2 |
| 8 | **ç¤¾äº¤å£°é‡ç©ºæ•°æ®** | ğŸŸ¡ ä¸­ç­‰ | æ˜¾ç¤º"æš‚æ— "ä½†æœ‰åˆ†ææ–‡å­— | æ•°æ®ä¸ä¸€è‡´ | P2 |
| 9 | **äº¤å‰éªŒè¯0%** | ğŸŸ¡ ä¸­ç­‰ | ä¸€è‡´æ€§0%, æ— ç¤¾äº¤æ•°æ® | éªŒè¯åŠŸèƒ½å¤±æ•ˆ | P2 |
| 10 | **äº§å‡ºåˆ†æè‹±æ–‡** | ğŸŸ¡ ä¸­ç­‰ | éƒ¨åˆ†æè¿°ä¸ºè‹±æ–‡ | ç”¨æˆ·ä½“éªŒä¸ä½³ | P2 |

---

## ğŸ” è¯¦ç»†é—®é¢˜åˆ†æ

### âŒ é—®é¢˜ 1: å­¦æœ¯æŒ‡æ ‡å®Œå…¨ä¸ºç©º (P0)

#### ç°çŠ¶
```html
<section id='scholar' class='section'>
    <h2>å­¦æœ¯æŒ‡æ ‡</h2>
    <div class='cards'>
        <div class='card'>
            <div class='card-title'>å­¦æœ¯æŒ‡æ ‡</div>
            <!-- å®Œå…¨ä¸ºç©ºï¼Œæ²¡æœ‰ä»»ä½•æ•°æ® -->
        </div>
    </div>
</section>
```

#### æ ¹æœ¬åŸå› 
1. **Google Scholaræ•°æ®æœªè·å–**
   - Scholar fetcher å¯èƒ½è¢«é˜»æ­¢æˆ–å¤±è´¥
   - æ²¡æœ‰æ‰¾åˆ°å€™é€‰äººçš„Google Scholar profile
   - ç½‘ç»œé—®é¢˜æˆ–APIé™åˆ¶

2. **åå­—æœç´¢å¤±è´¥**
   - ä¸­æ–‡å"æ—æŒº"æœç´¢ Google Scholar (è‹±æ–‡å¹³å°)
   - åº”è¯¥æœç´¢ "Ting Lin" + affiliation
   - å¯èƒ½éœ€è¦æ›´ç²¾ç¡®çš„æœç´¢ç­–ç•¥

#### ä¿®å¤æ–¹æ¡ˆ

**æ–¹æ¡ˆ A: å¢å¼ºScholaræœç´¢é€»è¾‘**
```python
# enricher.py - enrich_scholar_metrics()

def enrich_scholar_metrics(self, data: Dict[str, Any]) -> Dict[str, Any]:
    name = data.get("basic_info", {}).get("name", "")
    
    # æ–°å¢: å°è¯•å¤šç§åå­—å˜ä½“
    name_variants = self._generate_name_variants(name)
    
    for variant in name_variants:
        print(f"[å­¦æœ¯æŒ‡æ ‡] å°è¯•æœç´¢å˜ä½“: {variant}")
        metrics = self.scholar.run(name=variant, ...)
        if any(metrics.values()):
            print(f"[å­¦æœ¯æŒ‡æ ‡-æˆåŠŸ] ä½¿ç”¨å˜ä½“ '{variant}' æ‰¾åˆ°æ•°æ®")
            break
    
    # å¦‚æœä»ç„¶å¤±è´¥ï¼Œæ·»åŠ å ä½ç¬¦
    if not any(metrics.values()):
        print(f"[å­¦æœ¯æŒ‡æ ‡-å¤±è´¥] æœªèƒ½è·å– {name} çš„å­¦æœ¯æŒ‡æ ‡")
        # æ·»åŠ è¯´æ˜æ€§å ä½ç¬¦
        am["note"] = "æš‚æœªè·å–åˆ° Google Scholar æ•°æ®ï¼Œè¯·æ‰‹åŠ¨è¡¥å……æˆ–ç¨åé‡è¯•"
```

**æ–¹æ¡ˆ B: ä»è®ºæ–‡æ¨æ–­åŸºç¡€æŒ‡æ ‡**
```python
def _infer_metrics_from_publications(self, publications: List[Dict]) -> Dict:
    """ä»è®ºæ–‡åˆ—è¡¨æ¨æ–­åŸºç¡€å­¦æœ¯æŒ‡æ ‡"""
    if not publications:
        return {}
    
    # è®¡ç®—åŸºç¡€æŒ‡æ ‡
    total_pubs = len(publications)
    
    # æå–å¹´ä»½
    years = []
    for pub in publications:
        year = pub.get("year")
        if year:
            try:
                years.append(int(year))
            except:
                pass
    
    career_length = max(years) - min(years) + 1 if years else 0
    
    return {
        "total_publications": total_pubs,
        "career_years": career_length,
        "avg_per_year": round(total_pubs / career_length, 2) if career_length > 0 else 0,
        "source": "ä»è®ºæ–‡åˆ—è¡¨æ¨æ–­",
        "note": "å»ºè®®è¡¥å……Google Scholaræ•°æ®ä»¥è·å–å¼•ç”¨ä¿¡æ¯"
    }
```

**æ–¹æ¡ˆ C: æ˜¾ç¤ºå‹å¥½æç¤º**
```python
# render.py - å­¦æœ¯æŒ‡æ ‡section

if not academic_metrics or not any(academic_metrics.values()):
    scholar_html = """
    <div class='card warning-card'>
        <div class='card-title'>âš ï¸ å­¦æœ¯æŒ‡æ ‡æ•°æ®ç¼ºå¤±</div>
        <div class='content'>
            <p>æœªèƒ½è‡ªåŠ¨è·å– Google Scholar æ•°æ®ã€‚å¯èƒ½åŸå› ï¼š</p>
            <ul>
                <li>å€™é€‰äººæš‚æ—  Google Scholar æ¡£æ¡ˆ</li>
                <li>ç½‘ç»œé™åˆ¶æˆ–APIæš‚æ—¶ä¸å¯ç”¨</li>
                <li>åå­—æœç´¢åŒ¹é…å¤±è´¥</li>
            </ul>
            <p><strong>å»ºè®®ï¼š</strong>è¯·æ‰‹åŠ¨è¡¥å…… h-index å’Œå¼•ç”¨æ•°æ®ï¼Œæˆ–æä¾› Google Scholar ä¸ªäººä¸»é¡µé“¾æ¥ã€‚</p>
        </div>
    </div>
    """
else:
    # æ­£å¸¸æ˜¾ç¤º
```

---

### âŒ é—®é¢˜ 2: ä½œè€…è´¡çŒ®åº¦å…¨ä¸º0 (P0)

#### ç°çŠ¶
```html
<div class='metric-item'>
    <div class='label'>ç‹¬ç«‹æ€§å¾—åˆ†</div>
    <div class='value score-0'>0.00</div>  <!-- âŒ åº”è¯¥æ˜¯ >0 -->
</div>
<div class='metric-item'>
    <div class='label'>ç¬¬ä¸€ä½œè€…</div>
    <div class='value'>0 (0.0%)</div>  <!-- âŒ æ—æŒºæœ‰å¤šç¯‡è®ºæ–‡ -->
</div>
```

#### æ ¹æœ¬åŸå› 
**åå­—åŒ¹é…å¤±è´¥** - ä¸­æ–‡å vs è‹±æ–‡åé—®é¢˜

ç®€å†ä¸­:
- `basic_info.name`: "æ—æŒº" (ä¸­æ–‡)

è®ºæ–‡ä½œè€…åˆ—è¡¨ä¸­:
- `authors`: ['Jingpu Cheng', 'Qianxiao Li', **'Ting Lin'**, 'Zuowei Shen']

åŒ¹é…é—®é¢˜:
```python
candidate_name = "æ—æŒº"  # ä¸­æ–‡
normalized = "æ—æŒº"  # æ ‡å‡†åŒ–åä»æ˜¯ä¸­æ–‡

author = "Ting Lin"  # è‹±æ–‡
normalized_author = "ting lin"  # æ ‡å‡†åŒ–åæ˜¯è‹±æ–‡

# "æ—æŒº" != "ting lin"  âŒ åŒ¹é…å¤±è´¥
```

#### ä¿®å¤æ–¹æ¡ˆ

**æ–¹æ¡ˆ A: æ·»åŠ æ‹¼éŸ³/è‹±æ–‡åå­—æ®µ**
```python
# enricher.py - enrich_publications_authors()

def _extract_candidate_names(self, data: Dict[str, Any]) -> List[str]:
    """æå–å€™é€‰äººçš„æ‰€æœ‰å¯èƒ½åå­—å˜ä½“"""
    names = []
    
    # åŸå§‹åå­—
    name = data.get("basic_info", {}).get("name", "")
    if name:
        names.append(name)
    
    # è‹±æ–‡å (å¦‚æœæä¾›)
    english_name = data.get("basic_info", {}).get("english_name", "")
    if english_name:
        names.append(english_name)
    
    # ä»è®ºæ–‡ä½œè€…ä¸­æ¨æ–­
    publications = data.get("publications", [])
    potential_names = self._infer_candidate_name_from_publications(
        candidate_chinese=name,
        publications=publications
    )
    names.extend(potential_names)
    
    return list(set(names))
```

**æ–¹æ¡ˆ B: æ™ºèƒ½åå­—æ¨æ–­**
```python
def _infer_candidate_name_from_publications(
    self, 
    candidate_chinese: str, 
    publications: List[Dict]
) -> List[str]:
    """ä»è®ºæ–‡ä¸­æ¨æ–­å€™é€‰äººçš„è‹±æ–‡å"""
    
    # ç»Ÿè®¡ä½œè€…é¢‘ç‡
    author_counter = Counter()
    for pub in publications:
        authors = pub.get("authors", [])
        for author in authors:
            if isinstance(author, str):
                author_counter[author] += 1
    
    # æ‰¾å‡ºç°é¢‘ç‡æœ€é«˜çš„ä½œè€…ï¼ˆå¾ˆå¯èƒ½æ˜¯å€™é€‰äººï¼‰
    if author_counter:
        most_common = author_counter.most_common(3)
        print(f"[åå­—æ¨æ–­] é«˜é¢‘ä½œè€…: {most_common}")
        
        # è¿”å›å‡ºç°æ¬¡æ•°æœ€å¤šçš„3ä¸ªåå­—
        return [name for name, count in most_common if count >= len(publications) * 0.5]
    
    return []
```

**æ–¹æ¡ˆ C: ç”¨æˆ·ç•Œé¢æç¤º**
```python
# åœ¨ç”ŸæˆæŠ¥å‘Šå‰æç¤ºç”¨æˆ·
if not authorship_report or authorship_report.get("metrics", {}).get("independence_score", 0) == 0:
    print("\n" + "="*60)
    print("âš ï¸ è­¦å‘Š: ä½œè€…è´¡çŒ®åˆ†æå¯èƒ½ä¸å‡†ç¡®")
    print("="*60)
    print(f"å€™é€‰äººå§“å: {candidate_name}")
    print(f"è®ºæ–‡ä¸­çš„ä½œè€…å: {set(all_authors[:5])}")
    print("\nå»ºè®®:")
    print("1. åœ¨basic_infoä¸­æ·»åŠ  'english_name' å­—æ®µ")
    print("2. ç¡®ä¿è®ºæ–‡ä½œè€…åˆ—è¡¨ä¸­åå­—æ ¼å¼ä¸€è‡´")
    print("3. ç¤ºä¾‹: {\"basic_info\": {\"name\": \"æ—æŒº\", \"english_name\": \"Ting Lin\"}}")
    print("="*60 + "\n")
```

**æ–¹æ¡ˆ D: Pinyinè½¬æ¢**
```python
from pypinyin import lazy_pinyin

def _add_pinyin_variants(self, name: str) -> List[str]:
    """æ·»åŠ æ‹¼éŸ³å˜ä½“"""
    variants = [name]
    
    # å°è¯•æ‹¼éŸ³è½¬æ¢
    if self._is_chinese(name):
        # "æ—æŒº" -> ["lin", "ting"] -> "Lin Ting", "Ting Lin"
        pinyin_parts = lazy_pinyin(name)
        
        # é¦–å­—æ¯å¤§å†™
        pinyin_full = " ".join([p.capitalize() for p in pinyin_parts])
        variants.append(pinyin_full)  # "Lin Ting"
        
        # åå‘
        if len(pinyin_parts) == 2:
            reversed_name = f"{pinyin_parts[1].capitalize()} {pinyin_parts[0].capitalize()}"
            variants.append(reversed_name)  # "Ting Lin"
    
    return variants

def _is_chinese(self, text: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦"""
    return any('\u4e00' <= char <= '\u9fff' for char in text)
```

---

### âŒ é—®é¢˜ 3: é£é™©è¯„ä¼°ä½¿ç”¨è‹±æ–‡ (P0)

#### ç°çŠ¶
```html
<div class='risk-title'><strong>Low first-author publication rate (0.0%)</strong></div>
<div class='risk-desc'>ğŸ“Š Only 0 out of 16 publications are first-author.</div>
<div class='risk-implication'>âš ï¸ May indicate heavy reliance on advisor/collaborators...</div>
```

**å®Œå…¨æ˜¯è‹±æ–‡ï¼** ç”¨æˆ·ä½“éªŒæå·®ã€‚

#### æ ¹æœ¬åŸå› 
`utils/risk_assessment.py` ä¸­çš„ Risk å¯¹è±¡æ‰€æœ‰æ–‡æœ¬éƒ½æ˜¯ç¡¬ç¼–ç çš„è‹±æ–‡

```python
# risk_assessment.py
risks.append(Risk(
    category=RiskCategory.INDEPENDENCE,
    severity=RiskSeverity.HIGH,
    title="Low first-author publication rate (0.0%)",  # âŒ è‹±æ–‡
    detail=f"Only {first_author_count} out of {total_pubs} publications are first-author.",
    implication="May indicate heavy reliance on advisor/collaborators...",
    mitigation=[
        "Request detailed statement on independent research plans",
        "Interview should probe candidate's ability to formulate original research questions",
        "Contact references specifically about independence"
    ]
))
```

#### ä¿®å¤æ–¹æ¡ˆ

**æ–¹æ¡ˆ A: å›½é™…åŒ– (i18n) - æœ€å½»åº•**
```python
# utils/risk_assessment.py

class RiskTranslations:
    """é£é™©è¯„ä¼°æ–‡æœ¬ç¿»è¯‘"""
    
    ZH_CN = {
        "low_first_author_rate": {
            "title": "ç¬¬ä¸€ä½œè€…è®ºæ–‡æ¯”ä¾‹è¿‡ä½ ({rate})",
            "detail": "{total_pubs}ç¯‡è®ºæ–‡ä¸­ä»…{first_author_count}ç¯‡ä¸ºç¬¬ä¸€ä½œè€…ã€‚",
            "implication": "å¯èƒ½è¿‡åº¦ä¾èµ–å¯¼å¸ˆ/åˆä½œè€…ï¼Œç‹¬ç«‹ç ”ç©¶èƒ½åŠ›å­˜ç–‘ã€‚",
            "mitigation": [
                "è¦æ±‚æä¾›ç‹¬ç«‹ç ”ç©¶è®¡åˆ’è¯¦ç»†è¯´æ˜",
                "é¢è¯•æ—¶æ¢æŸ¥å€™é€‰äººæå‡ºåŸåˆ›ç ”ç©¶é—®é¢˜çš„èƒ½åŠ›",
                "è”ç³»æ¨èäººspecificallyéªŒè¯ç‹¬ç«‹æ€§"
            ]
        },
        "no_corresponding_author": {
            "title": "æ— é€šè®¯ä½œè€…è®ºæ–‡",
            "detail": "å€™é€‰äººä»æœªæ‹…ä»»ä»»ä½•è®ºæ–‡çš„é€šè®¯ä½œè€…ã€‚",
            "implication": "å¯èƒ½æœªä¸»å¯¼è¿‡å®Œæ•´ç ”ç©¶é¡¹ç›®ï¼Œé¢†å¯¼ç»éªŒä¸æ˜ç¡®ã€‚",
            "mitigation": [
                "æ¨èäººéªŒè¯æ—¶ä¸“é—¨è¯¢é—®ç ”ç©¶é¢†å¯¼åŠ›",
                "è¦æ±‚æä¾›é¡¹ç›®é¢†å¯¼ç»éªŒå®ä¾‹"
            ]
        },
        # ... æ›´å¤šç¿»è¯‘
    }
    
    EN_US = {
        # è‹±æ–‡ç‰ˆæœ¬
    }

class RiskAssessor:
    def __init__(self, current_year: int = None, language: str = "zh_CN"):
        self.current_year = current_year or datetime.now().year
        self.language = language
        self.translations = RiskTranslations.ZH_CN if language == "zh_CN" else RiskTranslations.EN_US
    
    def assess_research_independence(self, data: Dict[str, Any]) -> List[Risk]:
        # ...
        
        if first_author_rate < 0.3:
            trans = self.translations["low_first_author_rate"]
            risks.append(Risk(
                category=RiskCategory.INDEPENDENCE,
                severity=RiskSeverity.HIGH,
                title=trans["title"].format(rate=f"{first_author_rate:.1%}"),
                detail=trans["detail"].format(
                    total_pubs=total_pubs,
                    first_author_count=first_author_count
                ),
                implication=trans["implication"],
                mitigation=trans["mitigation"]
            ))
```

**æ–¹æ¡ˆ B: å¿«é€Ÿä¿®å¤ - ç›´æ¥ä¸­æ–‡åŒ–**
```python
# ç›´æ¥ä¿®æ”¹ risk_assessment.py ä¸­çš„æ‰€æœ‰è‹±æ–‡å­—ç¬¦ä¸²

# ç¤ºä¾‹ï¼š
risks.append(Risk(
    category=RiskCategory.INDEPENDENCE,
    severity=RiskSeverity.HIGH,
    title=f"ç¬¬ä¸€ä½œè€…è®ºæ–‡æ¯”ä¾‹è¿‡ä½ ({first_author_rate:.1%})",
    detail=f"{total_pubs}ç¯‡è®ºæ–‡ä¸­ä»…{first_author_count}ç¯‡ä¸ºç¬¬ä¸€ä½œè€…ã€‚",
    implication="å¯èƒ½è¿‡åº¦ä¾èµ–å¯¼å¸ˆ/åˆä½œè€…ï¼Œç‹¬ç«‹ç ”ç©¶èƒ½åŠ›å­˜ç–‘ã€‚",
    mitigation=[
        "è¦æ±‚æä¾›ç‹¬ç«‹ç ”ç©¶è®¡åˆ’è¯¦ç»†è¯´æ˜",
        "é¢è¯•æ—¶æ¢æŸ¥å€™é€‰äººæå‡ºåŸåˆ›ç ”ç©¶é—®é¢˜çš„èƒ½åŠ›",
        "è”ç³»æ¨èäººç‰¹åˆ«éªŒè¯ç‹¬ç«‹æ€§"
    ],
    red_flag=True
))
```

**æ–¹æ¡ˆ C: æšä¸¾ç±»ä¸­æ–‡åŒ–**
```python
# risk_assessment.py

class RiskCategory(Enum):
    """é£é™©ç±»åˆ«"""
    INDEPENDENCE = "ç ”ç©¶ç‹¬ç«‹æ€§"  # æ”¹ä¸ºä¸­æ–‡
    PRODUCTIVITY = "å­¦æœ¯äº§å‡º"
    INTEGRITY = "å­¦æœ¯è¯šä¿¡"
    COLLABORATION = "åˆä½œèƒ½åŠ›"
    RELEVANCE = "é¢†åŸŸç›¸å…³æ€§"
    TEACHING = "æ•™å­¦èƒ½åŠ›"

class RiskSeverity(Enum):
    """é£é™©ä¸¥é‡ç¨‹åº¦"""
    CRITICAL = "ä¸¥é‡"
    HIGH = "é«˜"
    MEDIUM = "ä¸­"
    LOW = "ä½"
```

---

### âŒ é—®é¢˜ 4: è¯æ®é“¾è¿½æº¯ä¸ºç©º (P1)

#### ç°çŠ¶
```html
<section id='evidence-chain' class='section'>
    <h2>ğŸ” è¯æ®é“¾è¿½æº¯</h2>
    <div class='cards'>
        <div class='card evidence-card'>
            <div class='card-title'>ğŸ” å­¦æœ¯åˆ›æ–°åŠ›</div>
            <!-- å®Œå…¨ä¸ºç©ºï¼Œæ²¡æœ‰claims -->
        </div>
        <!-- å…¶ä»–4ä¸ªç»´åº¦ä¹Ÿéƒ½ä¸ºç©º -->
    </div>
</section>
```

#### æ ¹æœ¬åŸå› 
1. **LLMæœªç”Ÿæˆclaims**
   - `build_evidence_chains_for_evaluation()` ä¾èµ–LLMä»è¯„ä»·æ–‡æœ¬ä¸­æå–å£°æ˜
   - LLMå¯èƒ½è¿”å›ç©ºç»“æœæˆ–é”™è¯¯æ ¼å¼

2. **è¯„ä»·æ–‡æœ¬å¯èƒ½å¤ªçŸ­**
   - `multi_dimension_evaluation` è¿”å›çš„æ–‡æœ¬ä¸å¤Ÿè¯¦ç»†
   - LLMæ— æ³•ä»ä¸­æå–è¶³å¤Ÿçš„claims

3. **æ•°æ®ç»“æ„ä¸åŒ¹é…**
   ```python
   # enhanced_evaluation æœŸæœ›ç»“æ„:
   {
       "å­¦æœ¯åˆ›æ–°åŠ›": {
           "claims": [
               {
                   "claim": "åœ¨è®¡ç®—æ•°å­¦é¢†åŸŸæœ‰ç³»ç»Ÿæˆæœ",
                   "confidence_score": 0.85,
                   "evidence": [...]
               }
           ]
       }
   }
   ```

#### ä¿®å¤æ–¹æ¡ˆ

**æ–¹æ¡ˆ A: æ”¹è¿›LLMæç¤ºè¯**
```python
# utils/evidence_chain.py

def _extract_claims_from_text(self, dimension_text: str) -> List[Dict]:
    """ä»ç»´åº¦è¯„ä»·æ–‡æœ¬ä¸­æå–å£°æ˜"""
    
    # æ”¹è¿›çš„æç¤ºè¯
    prompt = f"""
è¯·ä»ä»¥ä¸‹è¯„ä»·æ–‡æœ¬ä¸­æå–3-5ä¸ªå…³é”®å£°æ˜ï¼ˆclaimsï¼‰ã€‚æ¯ä¸ªå£°æ˜åº”è¯¥ï¼š
1. æ˜¯ä¸€ä¸ªå…·ä½“çš„ã€å¯éªŒè¯çš„é™ˆè¿°
2. å…³äºå€™é€‰äººçš„èƒ½åŠ›ã€æˆå°±æˆ–ç‰¹å¾
3. å¯ä»¥é€šè¿‡è¯æ®æ”¯æŒ

è¯„ä»·æ–‡æœ¬ï¼š
{dimension_text}

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼Œç¤ºä¾‹ï¼š
{{
  "claims": [
    {{
      "claim": "åœ¨ç¥ç»ç½‘ç»œç†è®ºæ–¹é¢æœ‰çªç ´æ€§æˆæœ",
      "confidence": 0.9,
      "keywords": ["ç¥ç»ç½‘ç»œ", "ç†è®º", "NeurIPS"]
    }},
    ...
  ]
}}

æ³¨æ„ï¼š
- ä½¿ç”¨ä¸­æ–‡
- confidenceèŒƒå›´0-1
- è‡³å°‘æå–3ä¸ªå£°æ˜
"""
    
    response = self.llm.chat([{"role": "user", "content": prompt}])
    
    try:
        result = json.loads(response)
        return result.get("claims", [])
    except:
        print(f"[è¯æ®é“¾] LLMè¿”å›è§£æå¤±è´¥: {response[:100]}")
        return []
```

**æ–¹æ¡ˆ B: å›é€€ç­–ç•¥ - ä»è®ºæ–‡ç›´æ¥ç”Ÿæˆ**
```python
def _generate_evidence_chains_fallback(
    self,
    dimension_name: str,
    resume_data: Dict[str, Any]
) -> Dict:
    """å½“LLMå¤±è´¥æ—¶çš„å›é€€ç­–ç•¥"""
    
    publications = resume_data.get("publications", [])
    awards = resume_data.get("awards", [])
    
    if not publications and not awards:
        return {"claims": []}
    
    # æ ¹æ®ç»´åº¦ç±»å‹ç”Ÿæˆclaims
    if dimension_name == "å­¦æœ¯åˆ›æ–°åŠ›":
        claims = []
        
        # ä»è®ºæ–‡ç”Ÿæˆ
        top_pubs = publications[:3]
        for pub in top_pubs:
            claims.append({
                "claim": f"å‘è¡¨è®ºæ–‡ã€Š{pub.get('title', '')}ã€‹",
                "confidence_score": 0.95,
                "evidence": [{
                    "type": "è®ºæ–‡",
                    "description": pub.get('title', ''),
                    "url": pub.get('url', ''),
                    "source": pub.get('venue', '')
                }]
            })
        
        # ä»å¥–é¡¹ç”Ÿæˆ
        for award in awards[:2]:
            claims.append({
                "claim": f"è·å¾—{award.get('title', '')}",
                "confidence_score": 1.0,
                "evidence": [{
                    "type": "å¥–é¡¹",
                    "description": award.get('description', ''),
                    "year": award.get('year', '')
                }]
            })
        
        return {"claims": claims}
```

**æ–¹æ¡ˆ C: æ˜¾ç¤ºå‹å¥½æç¤º**
```python
# render.py

if not enhanced_evaluation or not any(
    dim_data.get("claims") for dim_data in enhanced_evaluation.values()
):
    evidence_html = """
    <div class='card warning-card'>
        <div class='card-title'>âš ï¸ è¯æ®é“¾æ•°æ®ç¼ºå¤±</div>
        <div class='content'>
            <p>è¯æ®é“¾è¿½æº¯åŠŸèƒ½éœ€è¦LLMä»è¯„ä»·æ–‡æœ¬ä¸­æå–å…³é”®å£°æ˜ã€‚</p>
            <p>å½“å‰æœªèƒ½ç”Ÿæˆè¯æ®é“¾ï¼Œå¯èƒ½åŸå› ï¼š</p>
            <ul>
                <li>LLMå“åº”è¶…æ—¶æˆ–æ ¼å¼é”™è¯¯</li>
                <li>è¯„ä»·æ–‡æœ¬ä¸å¤Ÿè¯¦ç»†</li>
                <li>ç½‘ç»œè¿æ¥é—®é¢˜</li>
            </ul>
            <p><strong>å»ºè®®ï¼š</strong>æŸ¥çœ‹æ—¥å¿—ä¸­çš„ [è¯æ®é“¾] ç›¸å…³è¾“å‡ºï¼Œæˆ–é‡æ–°è¿è¡Œç”Ÿæˆæµç¨‹ã€‚</p>
        </div>
    </div>
    """
```

---

### âŒ é—®é¢˜ 5: ç ”ç©¶è„‰ç»œè¿ç»­æ€§å¾—åˆ†ä¸º0 (P1)

#### ç°çŠ¶
```html
<div class='metric-item'>
    <span class='label'>è¿ç»­æ€§å¾—åˆ†</span>
    <span class='value'>0.00</span>  <!-- âŒ åº”è¯¥ > 0 -->
</div>
<div class='metric-item'>
    <span class='label'>ç ”ç©¶æˆç†Ÿåº¦</span>
    <span class='value'>Unknown</span>  <!-- âŒ åº”è¯¥æœ‰å…·ä½“å€¼ -->
</div>
```

#### æ ¹æœ¬åŸå› 
å°½ç®¡ä¹‹å‰ä¿®å¤äº†keyåç§°é—®é¢˜ï¼ˆ`publications` vs `Publications`ï¼‰ï¼Œä½†ä»ç„¶è¿”å›0ï¼Œå¯èƒ½æ˜¯ï¼š

1. **æ•°æ®ä¸ºç©º**
   ```python
   publications = data.get("publications") or data.get("Publications") or []
   education = data.get("education") or data.get("Education") or []
   
   if not publications:  # âŒ å¦‚æœpublicationsä¸ºç©º
       return {"continuity_score": 0, "maturity": "Unknown"}
   ```

2. **å¹´ä»½ç¼ºå¤±**
   ```python
   # å¦‚æœè®ºæ–‡æ²¡æœ‰yearå­—æ®µ
   for pub in publications:
       year = pub.get("year")  # None
       if not year:
           continue  # è·³è¿‡è¯¥è®ºæ–‡
   
   # å¦‚æœæ‰€æœ‰è®ºæ–‡éƒ½æ²¡æœ‰yearï¼Œtimelineä¸ºç©º
   if not timeline:
       return {"continuity_score": 0}
   ```

3. **ä¸»é¢˜æå–å¤±è´¥**
   ```python
   topics = self._extract_topics_from_title(pub.get("title", ""))
   if not topics:  # å¦‚æœæå–ä¸åˆ°ä¸»é¢˜
       # æ— æ³•è®¡ç®—ä¸»é¢˜è¿ç»­æ€§
   ```

#### ä¿®å¤æ–¹æ¡ˆ

**æ–¹æ¡ˆ A: æ•°æ®éªŒè¯å’Œæ—¥å¿—**
```python
# utils/research_lineage.py

def analyze(self, resume_data: Dict[str, Any]) -> Dict[str, Any]:
    """åˆ†æç ”ç©¶è„‰ç»œ"""
    
    # æ•°æ®éªŒè¯
    publications = resume_data.get("publications") or resume_data.get("Publications") or []
    education = resume_data.get("education") or resume_data.get("Education") or []
    
    print(f"[ç ”ç©¶è„‰ç»œ] è¾“å…¥æ•°æ®: publications={len(publications)}, education={len(education)}")
    
    if not publications:
        print("[ç ”ç©¶è„‰ç»œ-è­¦å‘Š] è®ºæ–‡åˆ—è¡¨ä¸ºç©º")
        return self._empty_result()
    
    # æ£€æŸ¥è®ºæ–‡å¹´ä»½
    pubs_with_year = [p for p in publications if p.get("year")]
    print(f"[ç ”ç©¶è„‰ç»œ] æœ‰å¹´ä»½çš„è®ºæ–‡: {len(pubs_with_year)}/{len(publications)}")
    
    if len(pubs_with_year) < 3:
        print(f"[ç ”ç©¶è„‰ç»œ-è­¦å‘Š] è‡³å°‘éœ€è¦3ç¯‡æœ‰å¹´ä»½çš„è®ºæ–‡ï¼Œå½“å‰ä»…{len(pubs_with_year)}ç¯‡")
        return self._empty_result()
    
    # ç»§ç»­åˆ†æ...
    result = self._analyze_continuity(publications)
    print(f"[ç ”ç©¶è„‰ç»œ-å®Œæˆ] è¿ç»­æ€§å¾—åˆ†: {result.get('continuity_score', 0):.2f}")
    
    return result

def _empty_result(self) -> Dict[str, Any]:
    """è¿”å›ç©ºç»“æœ"""
    return {
        "continuity_score": 0.0,
        "maturity": "Unknown",
        "assessment": "æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œç ”ç©¶è„‰ç»œåˆ†æ",
        "academic_lineage": {},
        "research_trajectory": {},
        "note": "è‡³å°‘éœ€è¦3ç¯‡åŒ…å«å¹´ä»½ä¿¡æ¯çš„è®ºæ–‡"
    }
```

**æ–¹æ¡ˆ B: å¹´ä»½æ¨æ–­**
```python
def _infer_year_from_context(self, pub: Dict) -> Optional[int]:
    """ä»ä¸Šä¸‹æ–‡æ¨æ–­è®ºæ–‡å¹´ä»½"""
    
    # 1. ä»venueå­—ç¬¦ä¸²ä¸­æå–å¹´ä»½
    venue = pub.get("venue", "")
    year_match = re.search(r'\b(19|20)\d{2}\b', venue)
    if year_match:
        return int(year_match.group())
    
    # 2. ä»titleä¸­æå–
    title = pub.get("title", "")
    year_match = re.search(r'\b(19|20)\d{2}\b', title)
    if year_match:
        return int(year_match.group())
    
    # 3. ä»URLä¸­æå–
    url = pub.get("url", "")
    year_match = re.search(r'/(19|20)\d{2}/', url)
    if year_match:
        return int(year_match.group(1))
    
    return None
```

**æ–¹æ¡ˆ C: é™ä½æ•°æ®è¦æ±‚**
```python
def _analyze_continuity_relaxed(self, publications: List[Dict]) -> float:
    """æ”¾å®½çš„è¿ç»­æ€§åˆ†æ"""
    
    # å³ä½¿åªæœ‰2ç¯‡è®ºæ–‡ä¹Ÿå°è¯•åˆ†æ
    if len(publications) >= 2:
        # è®¡ç®—ä¸»é¢˜é‡å 
        topics = []
        for pub in publications:
            pub_topics = self._extract_topics(pub.get("title", ""))
            topics.extend(pub_topics)
        
        # è®¡ç®—ä¸»é¢˜å¤šæ ·æ€§
        unique_topics = set(topics)
        if len(topics) > 0:
            diversity = len(unique_topics) / len(topics)
            # è¿ç»­æ€§ = 1 - å¤šæ ·æ€§
            continuity = 1 - diversity
            return max(0.1, continuity)  # è‡³å°‘è¿”å›0.1
    
    return 0.0
```

---

### âŒ é—®é¢˜ 6: å‚è€ƒæ¥æºæ•°é‡ä¸º0 (P1)

#### ç°çŠ¶
```html
<section id='sources' class='section'>
    <h2>å‚è€ƒæ¥æº <span class='hbadge'>0</span></h2>
    <ul class='sources'>
        <li class='empty-card'>æš‚æ— </li>
    </ul>
</section>
```

#### æ ¹æœ¬åŸå› 
`profile_sources` åˆ—è¡¨æœªè¢«å¡«å……

```python
# render.py
prof_sources = data.get("profile_sources") or []  # ç©ºåˆ—è¡¨

# enricher.py - enrich_scholar_metrics()
if profile_url:
    srcs = data.get("profile_sources") or []
    srcs.append(profile_url)
    data["profile_sources"] = list(dict.fromkeys(srcs))

# ä½†å¦‚æœprofile_urlä¸ºç©ºï¼Œsourceså°±ä¸ä¼šè¢«å¡«å……
```

#### ä¿®å¤æ–¹æ¡ˆ

**æ–¹æ¡ˆ A: æ”¶é›†æ‰€æœ‰URLæ¥æº**
```python
# enricher.py - generate_final()

def _collect_all_sources(self, data: Dict[str, Any]) -> List[str]:
    """æ”¶é›†æ‰€æœ‰å‚è€ƒæ¥æºURL"""
    sources = set()
    
    # 1. ä»è®ºæ–‡URL
    for pub in data.get("publications", []):
        url = pub.get("url")
        if url and url.startswith("http"):
            sources.add(url)
    
    # 2. ä»å¥–é¡¹URL
    for award in data.get("awards", []):
        url = award.get("url")
        if url and url.startswith("http"):
            sources.add(url)
    
    # 3. ä»ç¤¾äº¤åª’ä½“
    for sp in data.get("social_presence", []):
        url = sp.get("url")
        if url and url.startswith("http"):
            sources.add(url)
    
    # 4. ä»Google Scholar
    scholar_url = data.get("basic_info", {}).get("academic_metrics", {}).get("profile_url")
    if scholar_url:
        sources.add(scholar_url)
    
    # 5. ä»åŸå§‹profile_sources
    existing_sources = data.get("profile_sources", [])
    sources.update(existing_sources)
    
    return list(sources)

# åœ¨generate_final()æœ«å°¾
final_obj["profile_sources"] = self._collect_all_sources(data)
```

**æ–¹æ¡ˆ B: ç”Ÿæˆè™šæ‹Ÿæ¥æº**
```python
def _generate_placeholder_sources(self, data: Dict[str, Any]) -> List[str]:
    """ç”Ÿæˆå ä½ç¬¦æ¥æºè¯´æ˜"""
    sources = []
    
    # åŸºæœ¬ä¿¡æ¯æ¥æº
    name = data.get("basic_info", {}).get("name", "")
    if name:
        sources.append(f"ç®€å†æ–‡ä»¶ - {name}")
    
    # è®ºæ–‡æ•°é‡
    pub_count = len(data.get("publications", []))
    if pub_count > 0:
        sources.append(f"å­¦æœ¯è®ºæ–‡æ•°æ®åº“æŸ¥è¯¢ - {pub_count}ç¯‡è®ºæ–‡")
    
    # å¥–é¡¹æ¥æº
    award_count = len(data.get("awards", []))
    if award_count > 0:
        sources.append(f"å¥–é¡¹è®°å½• - {award_count}ä¸ªå¥–é¡¹")
    
    return sources
```

**æ–¹æ¡ˆ C: æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡**
```python
# render.py - sources section

sources_html = ""
if not prof_sources:
    # ç»Ÿè®¡å®é™…æ•°æ®æ¥æº
    pub_urls = [p.get("url") for p in data.get("publications", []) if p.get("url")]
    award_urls = [a.get("url") for a in data.get("awards", []) if a.get("url")]
    
    sources_html = f"""
    <div class='card'>
        <div class='card-title'>ğŸ“Š æ•°æ®æ¥æºç»Ÿè®¡</div>
        <div class='content'>
            <ul>
                <li>è®ºæ–‡é“¾æ¥: {len(pub_urls)} ä¸ª</li>
                <li>å¥–é¡¹é“¾æ¥: {len(award_urls)} ä¸ª</li>
                <li>åŸºæœ¬ä¿¡æ¯: ç®€å†æ–‡ä»¶</li>
            </ul>
            <p><strong>è¯´æ˜ï¼š</strong>è¯¦ç»†URLé“¾æ¥å·²å†…åµŒåœ¨å„ä¸ªæ¨¡å—ä¸­ï¼Œå¯ç‚¹å‡»ç›¸åº”é“¾æ¥æŸ¥çœ‹ã€‚</p>
        </div>
    </div>
    """
else:
    # æ­£å¸¸æ˜¾ç¤ºsourcesåˆ—è¡¨
```

---

### âš ï¸ é—®é¢˜ 7: è´¨é‡å¾—åˆ†ä¸º0 (P2)

#### ç°çŠ¶
```html
<div class='balance-item'>
    <span class='label'>è´¨é‡å¾—åˆ†</span>
    <span class='value'>0.0</span>  <!-- âŒ åº”è¯¥ > 0 -->
</div>
```

#### æ ¹æœ¬åŸå› 
è´¨é‡å¾—åˆ†ä¾èµ–äº**å¼•ç”¨æ•°æ®**ï¼ˆcitationsï¼‰ï¼Œè€Œå¼•ç”¨æ•°æ®æ¥è‡ªGoogle Scholarã€‚

```python
# utils/productivity_timeline.py

def _calculate_quality_score(self, publications: List[Dict]) -> float:
    """è®¡ç®—è´¨é‡å¾—åˆ†"""
    
    total_citations = 0
    for pub in publications:
        citations = pub.get("citations", 0)  # âŒ å¦‚æœæ²¡æœ‰citationså­—æ®µ
        total_citations += int(citations) if citations else 0
    
    if total_citations == 0:  # æ²¡æœ‰å¼•ç”¨æ•°æ®
        return 0.0  # è¿”å›0
```

è¿™ä¸**é—®é¢˜1ï¼ˆå­¦æœ¯æŒ‡æ ‡ä¸ºç©ºï¼‰**æ˜¯è¿é”ååº”ã€‚

#### ä¿®å¤æ–¹æ¡ˆ

**æ–¹æ¡ˆ A: åŸºäºvenueè´¨é‡è¯„åˆ†**
```python
def _calculate_quality_score_alternative(self, publications: List[Dict]) -> float:
    """åŸºäºå‘è¡¨venueçš„æ›¿ä»£è´¨é‡è¯„åˆ†"""
    
    # é¡¶çº§ä¼šè®®/æœŸåˆŠåˆ—è¡¨
    top_venues = {
        "NeurIPS": 10,
        "ICML": 10,
        "ICLR": 10,
        "CVPR": 9,
        "ICCV": 9,
        "Nature": 10,
        "Science": 10,
        "SIAM": 8,
        "IEEE": 7,
        # ... æ›´å¤š
    }
    
    total_score = 0
    for pub in publications:
        venue = pub.get("venue", "")
        
        # åŒ¹é…é¡¶çº§venue
        score = 0
        for top_venue, venue_score in top_venues.items():
            if top_venue.lower() in venue.lower():
                score = venue_score
                break
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œç»™äºˆåŸºç¡€åˆ†
        if score == 0:
            score = 5
        
        total_score += score
    
    # å½’ä¸€åŒ–åˆ°0-10
    if publications:
        avg_score = total_score / len(publications)
        return min(10.0, avg_score)
    
    return 0.0
```

**æ–¹æ¡ˆ B: åŸºäºæœŸåˆŠåˆ†åŒº**
```python
def _extract_journal_tier(self, pub: Dict) -> int:
    """ä»è®ºæ–‡ä¿¡æ¯æå–æœŸåˆŠåˆ†åŒº"""
    
    # ä»venueæˆ–notesä¸­æå– "ä¸€åŒº", "äºŒåŒº" ç­‰
    venue = pub.get("venue", "")
    notes = pub.get("notes", "")
    text = venue + " " + notes
    
    if "ä¸€åŒº" in text or "Q1" in text or "Top" in text:
        return 10
    elif "äºŒåŒº" in text or "Q2" in text:
        return 8
    elif "ä¸‰åŒº" in text or "Q3" in text:
        return 6
    elif "å››åŒº" in text or "Q4" in text:
        return 4
    else:
        return 5  # é»˜è®¤ä¸­ç­‰
```

**æ–¹æ¡ˆ C: æ˜¾ç¤ºè¯´æ˜**
```python
# render.py

if quality_score == 0:
    quality_html = """
    <div class='balance-item'>
        <span class='label'>è´¨é‡å¾—åˆ†</span>
        <span class='value'>N/A</span>
        <span class='note'>ç¼ºå°‘å¼•ç”¨æ•°æ®</span>
    </div>
    """
```

---

### âš ï¸ é—®é¢˜ 8: ç¤¾äº¤å£°é‡ä¸ºç©ºä½†æœ‰æ–‡å­— (P2)

#### ç°çŠ¶
```html
<section id='social' class='section'>
    <h2>ç¤¾äº¤å£°é‡</h2>
    <div class='cards'>
        <div class='card empty-card'>
            <div class='content'>æš‚æ— </div>  <!-- âŒ æ˜¾ç¤º"æš‚æ— " -->
        </div>
    </div>
    <div class='card'>
        <div class='card-title'>å½±å“åŠ›</div>
        <div class='content'>
            æ—æŒºåœ¨ç¤¾äº¤åª’ä½“å¹³å°çš„æ•´ä½“æ´»è·ƒåº¦ç›¸å¯¹æœ‰é™...  <!-- âœ… ä½†æœ‰åˆ†ææ–‡å­— -->
        </div>
    </div>
</section>
```

**çŸ›ç›¾**: ä¸€è¾¹è¯´"æš‚æ— "ï¼Œä¸€è¾¹åˆæœ‰è¯¦ç»†çš„ç¤¾äº¤å½±å“åŠ›åˆ†ææ–‡å­—ã€‚

#### æ ¹æœ¬åŸå› 
```python
# render.py

social_presence = data.get("social_presence") or []  # ç©ºåˆ—è¡¨
social_influence = data.get("social_influence") or {}

# ç¬¬ä¸€ä¸ªcardï¼šæ˜¾ç¤ºsocial_presenceå¹³å°å¡ç‰‡
if not social_presence:  # ç©ºåˆ—è¡¨
    social_cards = "<div class='card empty-card'><div class='content'>æš‚æ— </div></div>"

# ç¬¬äºŒä¸ªcardï¼šæ˜¾ç¤ºsocial_influenceåˆ†æ
si_summary = social_influence.get("summary", "")
if si_summary:  # âœ… æœ‰summaryæ–‡å­—
    # æ˜¾ç¤ºåˆ†æ
```

é—®é¢˜ï¼š`social_presence`ä¸ºç©ºï¼Œä½†`social_influence`æœ‰å†…å®¹ï¼ˆLLMç”Ÿæˆçš„åˆ†æï¼‰

#### ä¿®å¤æ–¹æ¡ˆ

**æ–¹æ¡ˆ A: ç»Ÿä¸€æ˜¾ç¤ºé€»è¾‘**
```python
# render.py

social_html = ""

# å¦‚æœsocial_influenceæœ‰å†…å®¹ï¼Œå°±æ˜¾ç¤º
if social_influence and (social_influence.get("summary") or social_influence.get("signals")):
    social_html += """
    <div class='card'>
        <div class='card-title'>ğŸ“Š ç¤¾äº¤å½±å“åŠ›åˆ†æ</div>
        <div class='content'>
            {summary}
        </div>
    </div>
    """.format(summary=social_influence.get("summary", ""))
    
    # signals
    if social_influence.get("signals"):
        social_html += "<ul class='signal-list'>"
        for signal in social_influence["signals"]:
            social_html += f"<li>{signal}</li>"
        social_html += "</ul>"

# å¦‚æœæœ‰social_presenceå¹³å°ï¼Œä¹Ÿæ˜¾ç¤º
if social_presence:
    for sp in social_presence:
        # ... æ˜¾ç¤ºå¹³å°å¡ç‰‡

# å¦‚æœä¸¤è€…éƒ½æ²¡æœ‰
if not social_html:
    social_html = "<div class='card empty-card'><div class='content'>æš‚æ— ç¤¾äº¤åª’ä½“æ•°æ®</div></div>"
```

**æ–¹æ¡ˆ B: åŒºåˆ†æ•°æ®å’Œåˆ†æ**
```python
# æ˜ç¡®æ ‡æ³¨å“ªäº›æ˜¯å®é™…æ•°æ®ï¼Œå“ªäº›æ˜¯LLMåˆ†æ

<h2>ç¤¾äº¤å£°é‡</h2>

<h3>ğŸ“± ç¤¾äº¤åª’ä½“å¹³å°</h3>
<div class='cards'>
    <!-- social_presenceæ•°æ® -->
    {% if social_presence %}
        <!-- æ˜¾ç¤ºå¹³å°å¡ç‰‡ -->
    {% else %}
        <div class='card empty-card'>
            <div class='content'>æš‚æ— ç¤¾äº¤åª’ä½“å¹³å°æ•°æ®</div>
        </div>
    {% endif %}
</div>

<h3>ğŸ“Š å½±å“åŠ›åˆ†æï¼ˆAIç”Ÿæˆï¼‰</h3>
<div class='card'>
    <!-- social_influence.summary -->
    {{ social_influence.summary or "æš‚æ— åˆ†æ" }}
</div>
```

---

### âš ï¸ é—®é¢˜ 9: äº¤å‰éªŒè¯0% (P2)

#### ç°çŠ¶
```html
<div class='consistency-meter'>
    <div class='meter-fill' style='width: 0%'></div>
    <span class='meter-text'>0%</span>  <!-- âŒ 0% -->
</div>
<div class='all-consistent'>
    âœ¨ å­¦æœ¯ä¸ç¤¾äº¤ä¿¡å·é«˜åº¦ä¸€è‡´  <!-- âŒ ä½†å®é™…æ˜¯0% -->
</div>
```

#### æ ¹æœ¬åŸå› 
äº¤å‰éªŒè¯éœ€è¦**ç¤¾äº¤æ•°æ®**ï¼Œä½†`social_influence`ä¸ºç©ºæˆ–ä¸å®Œæ•´

```python
# enricher.py - generate_final()

social_data = data.get("social_influence", {})
if social_data and isinstance(dims, dict) and isinstance(social_data, dict):
    cross_validation = cross_validate_evaluation(
        academic_evaluation=dims,
        social_analysis=social_data
    )
else:
    # è·³è¿‡äº¤å‰éªŒè¯
```

#### ä¿®å¤æ–¹æ¡ˆ

**æ–¹æ¡ˆ A: å‹å¥½æç¤º**
```python
# render.py

if not cross_validation or cross_validation.get("consistency_score", 0) == 0:
    cross_val_html = """
    <div class='card warning-card'>
        <div class='card-title'>âš ï¸ äº¤å‰éªŒè¯ä¸å¯ç”¨</div>
        <div class='content'>
            <p>äº¤å‰éªŒè¯éœ€è¦å€™é€‰äººçš„ç¤¾äº¤åª’ä½“æ•°æ®ã€‚</p>
            <p><strong>å½“å‰çŠ¶æ€ï¼š</strong>ç¼ºå°‘ç¤¾äº¤åª’ä½“å¹³å°æ•°æ®</p>
            <p><strong>å»ºè®®ï¼š</strong>è¡¥å……å€™é€‰äººçš„Twitterã€LinkedInã€GitHubç­‰ç¤¾äº¤åª’ä½“ä¿¡æ¯</p>
        </div>
    </div>
    """
```

**æ–¹æ¡ˆ B: åŸºäºå…¶ä»–æ•°æ®æºéªŒè¯**
```python
def cross_validate_with_awards(
    academic_evaluation: Dict[str, Any],
    awards: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """ä½¿ç”¨å¥–é¡¹æ•°æ®è¿›è¡Œäº¤å‰éªŒè¯"""
    
    # ä»å­¦æœ¯è¯„ä»·ä¸­æå–å£°æ˜
    academic_claims = extract_claims(academic_evaluation)
    
    # ä»å¥–é¡¹ä¸­æå–æ”¯æŒä¿¡å·
    award_signals = []
    for award in awards:
        title = award.get("title", "")
        description = award.get("description", "")
        award_signals.append({
            "type": "è£èª‰è®¤å¯",
            "content": f"{title}: {description}",
            "year": award.get("year")
        })
    
    # è®¡ç®—ä¸€è‡´æ€§
    consistency_score = calculate_consistency(academic_claims, award_signals)
    
    return {
        "consistency_score": consistency_score,
        "source": "å­¦æœ¯è¯„ä»· vs å¥–é¡¹è£èª‰",
        "method": "æ›¿ä»£äº¤å‰éªŒè¯"
    }
```

---

### âš ï¸ é—®é¢˜ 10: äº§å‡ºåˆ†æéƒ¨åˆ†è‹±æ–‡ (P2)

#### ç°çŠ¶
```html
<div class='trend-assessment'>Stable-Positive - Maintaining good productivity with some improvements</div>
<div class='timeline-stats'>å¢é•¿ç‡: Strong growth (+400%)</div>
<div class='balance-assessment'>Quantity-focused - High output, moderate impact</div>
```

éƒ¨åˆ†è‹±æ–‡ï¼Œéƒ¨åˆ†ä¸­æ–‡ï¼Œä¸ç»Ÿä¸€ã€‚

#### ä¿®å¤æ–¹æ¡ˆ
```python
# utils/productivity_timeline.py

TREND_TRANSLATIONS = {
    "Accelerating": "åŠ é€Ÿå¢é•¿",
    "Stable-Positive": "ç¨³å®šå‘å¥½",
    "Declining": "ä¸‹é™è¶‹åŠ¿",
    "Strong growth": "å¼ºåŠ²å¢é•¿",
    "Quantity-focused": "æ•°é‡å¯¼å‘",
    "High-volume peak": "é«˜äº§å‡ºå³°å€¼",
    "Continued growth": "æŒç»­å¢é•¿",
    # ... æ›´å¤š
}

def translate_trend(english_text: str) -> str:
    """ç¿»è¯‘è¶‹åŠ¿æ–‡æœ¬"""
    for en, zh in TREND_TRANSLATIONS.items():
        english_text = english_text.replace(en, zh)
    return english_text
```

---

## ğŸ“ ä¿®å¤ä¼˜å…ˆçº§å’Œå®æ–½è®¡åˆ’

### ç¬¬ä¸€é˜¶æ®µ (P0 - å…³é”®é—®é¢˜) - 1-2å¤©

1. **é£é™©è¯„ä¼°ä¸­æ–‡åŒ–** (é—®é¢˜3)
   - å·¥ä½œé‡: 4å°æ—¶
   - ä¿®æ”¹æ–‡ä»¶: `utils/risk_assessment.py`
   - æ–¹æ³•: ç›´æ¥å°†æ‰€æœ‰è‹±æ–‡å­—ç¬¦ä¸²æ›¿æ¢ä¸ºä¸­æ–‡
   - æµ‹è¯•: è¿è¡Œé£é™©è¯„ä¼°ï¼Œæ£€æŸ¥è¾“å‡º

2. **ä½œè€…è´¡çŒ®åº¦åå­—åŒ¹é…** (é—®é¢˜2)
   - å·¥ä½œé‡: 6å°æ—¶
   - ä¿®æ”¹æ–‡ä»¶: `utils/authorship_analyzer.py`, `modules/resume_json/enricher.py`
   - æ–¹æ³•: æ·»åŠ æ‹¼éŸ³è½¬æ¢ + è‹±æ–‡åå­—æ®µ + æ™ºèƒ½æ¨æ–­
   - æµ‹è¯•: ç”¨æ—æŒºæ•°æ®æµ‹è¯•ï¼Œç¡®ä¿åŒ¹é…æˆåŠŸ

3. **å­¦æœ¯æŒ‡æ ‡å¢å¼º** (é—®é¢˜1)
   - å·¥ä½œé‡: 8å°æ—¶
   - ä¿®æ”¹æ–‡ä»¶: `modules/resume_json/enricher.py`, `modules/output/render.py`
   - æ–¹æ³•: å¤šå˜ä½“æœç´¢ + ä»è®ºæ–‡æ¨æ–­ + å‹å¥½æç¤º
   - æµ‹è¯•: æµ‹è¯•Scholar APIè°ƒç”¨å’Œå›é€€é€»è¾‘

### ç¬¬äºŒé˜¶æ®µ (P1 - é‡è¦é—®é¢˜) - 2-3å¤©

4. **ç ”ç©¶è„‰ç»œæ•°æ®éªŒè¯** (é—®é¢˜5)
   - å·¥ä½œé‡: 6å°æ—¶
   - ä¿®æ”¹æ–‡ä»¶: `utils/research_lineage.py`
   - æ–¹æ³•: æ·»åŠ æ—¥å¿— + æ•°æ®éªŒè¯ + æ”¾å®½è¦æ±‚
   - æµ‹è¯•: æ£€æŸ¥è¿ç»­æ€§å¾—åˆ†è®¡ç®—

5. **è¯æ®é“¾LLMæ”¹è¿›** (é—®é¢˜4)
   - å·¥ä½œé‡: 8å°æ—¶
   - ä¿®æ”¹æ–‡ä»¶: `utils/evidence_chain.py`
   - æ–¹æ³•: æ”¹è¿›æç¤ºè¯ + æ·»åŠ å›é€€ç­–ç•¥
   - æµ‹è¯•: éªŒè¯claimsç”Ÿæˆè´¨é‡

6. **å‚è€ƒæ¥æºæ”¶é›†** (é—®é¢˜6)
   - å·¥ä½œé‡: 4å°æ—¶
   - ä¿®æ”¹æ–‡ä»¶: `modules/resume_json/enricher.py`
   - æ–¹æ³•: æ”¶é›†æ‰€æœ‰URLæ¥æº
   - æµ‹è¯•: æ£€æŸ¥sourcesåˆ—è¡¨å¡«å……

### ç¬¬ä¸‰é˜¶æ®µ (P2 - æ”¹è¿›é—®é¢˜) - 1-2å¤©

7. **äº§å‡ºåˆ†æä¸­æ–‡åŒ–** (é—®é¢˜10)
   - å·¥ä½œé‡: 2å°æ—¶
   - ä¿®æ”¹æ–‡ä»¶: `utils/productivity_timeline.py`
   - æ–¹æ³•: ç¿»è¯‘å­—å…¸æ›¿æ¢

8. **è´¨é‡å¾—åˆ†ä¼˜åŒ–** (é—®é¢˜7)
   - å·¥ä½œé‡: 4å°æ—¶
   - ä¿®æ”¹æ–‡ä»¶: `utils/productivity_timeline.py`
   - æ–¹æ³•: åŸºäºvenueçš„æ›¿ä»£è¯„åˆ†

9. **ç¤¾äº¤å£°é‡ç»Ÿä¸€** (é—®é¢˜8)
   - å·¥ä½œé‡: 2å°æ—¶
   - ä¿®æ”¹æ–‡ä»¶: `modules/output/render.py`
   - æ–¹æ³•: ç»Ÿä¸€æ˜¾ç¤ºé€»è¾‘

10. **äº¤å‰éªŒè¯æç¤º** (é—®é¢˜9)
    - å·¥ä½œé‡: 2å°æ—¶
    - ä¿®æ”¹æ–‡ä»¶: `modules/output/render.py`
    - æ–¹æ³•: æ·»åŠ å‹å¥½æç¤º

---

## ğŸ§ª æµ‹è¯•è®¡åˆ’

### å•å…ƒæµ‹è¯•
```bash
# æµ‹è¯•åå­—åŒ¹é…
pytest tests/unit/test_authorship_analyzer.py -v

# æµ‹è¯•ç ”ç©¶è„‰ç»œ
pytest tests/unit/test_research_lineage.py -v

# æµ‹è¯•é£é™©è¯„ä¼°
pytest tests/unit/test_risk_assessment.py -v
```

### é›†æˆæµ‹è¯•
```bash
# ä½¿ç”¨æ—æŒºæ•°æ®ç«¯åˆ°ç«¯æµ‹è¯•
python -m modules.resume_json.enricher output/resume_rich.json

# æ£€æŸ¥ç”Ÿæˆçš„HTML
open output/resume_final.html
```

### å›å½’æµ‹è¯•æ¸…å•
- [ ] å­¦æœ¯æŒ‡æ ‡æ˜¾ç¤ºï¼ˆè‡³å°‘æ˜¾ç¤ºè®ºæ–‡æ•°ç»Ÿè®¡ï¼‰
- [ ] ä½œè€…è´¡çŒ®åº¦ > 0ï¼ˆè‡³å°‘åŒ¹é…åˆ°éƒ¨åˆ†è®ºæ–‡ï¼‰
- [ ] é£é™©è¯„ä¼°å…¨éƒ¨ä¸­æ–‡
- [ ] è¯æ®é“¾è‡³å°‘æœ‰éƒ¨åˆ†å†…å®¹
- [ ] ç ”ç©¶è„‰ç»œè¿ç»­æ€§ > 0
- [ ] å‚è€ƒæ¥æº > 0
- [ ] æ— è‹±æ–‡æ®‹ç•™ï¼ˆé™¤ä¸“ä¸šæœ¯è¯­ï¼‰
- [ ] ç¤¾äº¤å£°é‡æ˜¾ç¤ºä¸€è‡´
- [ ] äº¤å‰éªŒè¯æœ‰æç¤º
- [ ] äº§å‡ºåˆ†æå…¨ä¸­æ–‡

---

## ğŸ“Š é¢„æœŸæ”¹è¿›æ•ˆæœ

| æŒ‡æ ‡ | ä¿®å¤å‰ | ä¿®å¤å | æå‡ |
|-----|-------|-------|------|
| å­¦æœ¯æŒ‡æ ‡å®Œæ•´æ€§ | 0% | 80% | +80% |
| ä½œè€…è´¡çŒ®åº¦å‡†ç¡®æ€§ | 0% | 85% | +85% |
| é£é™©è¯„ä¼°å¯è¯»æ€§ | 20% | 100% | +80% |
| è¯æ®é“¾å®Œæ•´æ€§ | 0% | 70% | +70% |
| ç ”ç©¶è„‰ç»œå‡†ç¡®æ€§ | 0% | 75% | +75% |
| æ•´ä½“ç”¨æˆ·æ»¡æ„åº¦ | 40% | 90% | +50% |

---

## ğŸ’¡ é•¿æœŸä¼˜åŒ–å»ºè®®

### 1. æ•°æ®è´¨é‡ä¿éšœ
- æ·»åŠ æ•°æ®éªŒè¯layer
- è¾“å…¥æ—¶æ£€æŸ¥å¿…éœ€å­—æ®µ
- æä¾›æ•°æ®è´¨é‡æŠ¥å‘Š

### 2. å›½é™…åŒ– (i18n)
- å®Œæ•´çš„ä¸­è‹±æ–‡æ”¯æŒ
- é…ç½®æ–‡ä»¶æ§åˆ¶è¯­è¨€
- åŠ¨æ€åˆ‡æ¢ç•Œé¢è¯­è¨€

### 3. ç”¨æˆ·äº¤äº’æ”¹è¿›
- æ·»åŠ è¿›åº¦æ¡æ˜¾ç¤ºå¤„ç†è¿›åº¦
- å®æ—¶æ˜¾ç¤ºæ—¥å¿—è¾“å‡º
- å¤±è´¥æ—¶æä¾›è¯¦ç»†è¯Šæ–­

### 4. LLMè´¨é‡æå‡
- ä½¿ç”¨æ›´å¥½çš„æç¤ºå·¥ç¨‹
- æ·»åŠ few-shot examples
- å®æ–½ç»“æœéªŒè¯å’Œé‡è¯•æœºåˆ¶

### 5. æ€§èƒ½ä¼˜åŒ–
- ç¼“å­˜Scholar APIç»“æœ
- å¹¶è¡ŒåŒ–LLMè°ƒç”¨
- å¢é‡æ›´æ–°æœºåˆ¶

---

## ğŸš€ å¿«é€Ÿä¿®å¤è„šæœ¬

åˆ›å»ºä¸€ä¸ªå¿«é€Ÿä¿®å¤è„šæœ¬ï¼š

```python
# scripts/quick_fix.py

"""å¿«é€Ÿä¿®å¤10ä¸ªä¸»è¦é—®é¢˜çš„è„šæœ¬"""

def main():
    print("å¼€å§‹å¿«é€Ÿä¿®å¤...")
    
    # 1. ä¿®å¤é£é™©è¯„ä¼°ä¸­æ–‡åŒ–
    fix_risk_assessment_chinese()
    
    # 2. æ·»åŠ åå­—å˜ä½“æ”¯æŒ
    fix_authorship_name_matching()
    
    # 3. å¢å¼ºå­¦æœ¯æŒ‡æ ‡è·å–
    fix_scholar_metrics_fallback()
    
    # 4-10. å…¶ä»–ä¿®å¤...
    
    print("ä¿®å¤å®Œæˆï¼è¯·è¿è¡Œæµ‹è¯•éªŒè¯ã€‚")

if __name__ == "__main__":
    main()
```

---

## ğŸ“ è”ç³»ä¸æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ï¼š
- è¯¦ç»†æ—¥å¿—: `output/logs/*.log`
- é”™è¯¯æŠ¥å‘Š: `BUGFIX_UI_DISPLAY.md`
- æœ¬æ–‡æ¡£: `COMPREHENSIVE_ISSUES_ANALYSIS.md`

**Repository**: [WisdomEye](https://github.com/ywfan/WisdomEye)  
**Date**: 2025-12-16
